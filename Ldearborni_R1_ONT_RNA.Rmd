---
title: "Ldearborni_R1_liverRNA"
author: "Sam Bogan"
date: "2024-11-15"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

11/15/2024

### fast5 to pod5 conversion

```{bash}

#!/bin/bash
#SBATCH --job-name=Ld_R1_pod5_convert
#SBATCH --time=0-48:00:00
#SBATCH --mail-user=snbogan@ucsc.edu
#SBATCH --mail-type=ALL
#SBATCH --output=Ld_R1_pod5_convert.out
#SBATCH --error=Ld_R1_pod5_convert.err
#SBATCH --ntasks=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=8
#SBATCH --mem=68GB

# Move directories
cd /hb/home/snbogan/PolarFish/RNAseq/Ldear_run1/20240606_1038_MN32724_FAU44241_e56fb14d

# Load pod5
module load miniconda3

conda activate pod5

# Find all Fast5 files and split into 5 batches
files=(./fast5/*.fast5)
total_files=${#files[@]}
batch_size=$((total_files / 5))

echo "Total Fast5 files: $total_files"
echo "Batch size: $batch_size"

# Loop through 5 batches
for i in {0..4}; do
    start=$((i * batch_size))
    end=$((start + batch_size - 1))

    # For the last batch, make sure it includes any remaining files
    if [ $i -eq 4 ]; then
        end=$((total_files - 1))
    fi

    batch_files="${files[@]:$start:$((end - start + 1))}"

    # Run pod5 conversion for the current batch
    echo "Processing batch $((i + 1))..."
    pod5 convert fast5 $batch_files --output Ldearborni_R1_converted_batch_$((i + 1)).pod5

    # Check if the conversion was successful for this batch
    if [ -f "Ldearborni_R1_converted_batch_$((i + 1)).pod5" ]; then
        echo "Batch $((i + 1)) conversion successful"
    else
        echo "Batch $((i + 1)) conversion failed" >&2
        exit 1
    fi
done

echo "All batches processed successfully."


```

11/17/2024

### Basecalling with guppy

Tried using dorado, but the seqkit was too old and not compatible with the program. Guppy seems to be only option.

```{bash}

#!/bin/bash
#SBATCH --partition=96x24gpu4
#SBATCH --job-name=Ld_R1_guppy_parallel
#SBATCH --time=7-00:00:00
#SBATCH --mail-user=snbogan@ucsc.edu
#SBATCH --mail-type=ALL
#SBATCH --output=Ld_R1_guppy_%A_%a.out
#SBATCH --error=Ld_R1_guppy_%A_%a.err
#SBATCH --ntasks=1                   # Only one task for the parallel execution
#SBATCH --cpus-per-task=4            # Adjust CPU cores based on available resources
#SBATCH --gres=gpu:4                 # Request 4 GPUs
#SBATCH --mem=68GB                   # Shared memory for all tasks

# Move to the working directory
cd /hb/home/snbogan/PolarFish/RNAseq/Ldear_run1/20240606_1038_MN32724_FAU44241_e56fb14d

# Load guppy and parallel
module load guppy
module load parallel

# Get the list of input files (glob pattern)
INPUT_DIR="pod5s"
FILES=($(ls ${INPUT_DIR}/*.pod5))

# Number of files
NUM_FILES=${#FILES[@]}

# Calculate the number of files per task
FILES_PER_TASK=4

# Distribute files across tasks
for i in $(seq 0 $((NUM_FILES / FILES_PER_TASK))); do
  START_INDEX=$((i * FILES_PER_TASK))
  END_INDEX=$(((i + 1) * FILES_PER_TASK - 1))

  # Ensure we don't go out of bounds
  if [ $END_INDEX -ge $NUM_FILES ]; then
    END_INDEX=$((NUM_FILES - 1))
  fi

  # Slice the files to process
  FILES_TO_PROCESS="${FILES[@]:$START_INDEX:$((END_INDEX - START_INDEX + 1))}"

  # Run `guppy_basecaller` in parallel across 4 tasks
  parallel -j 4 --delay 0.1 --no-notice "guppy_basecaller \
    --input_path ${INPUT_DIR} \
    --save_path guppy_out_parallel/gpu_{#} \
    --flowcell FLO-MIN112 \
    --kit SQK-LSK112 \
    --compress_fastq \
    --device cuda:{#} " ::: ${FILES_TO_PROCESS[@]}
done

```

Passed reads (>phred = 7)
* 3.62 gb as fastq.gz
* Mean: 1047.68 bp Stddev: 1104.86 bp

# failed reads = (<phred = 7)
* 3.00 gb as fastq.gz
* Mean: 845.943 bp Stddev: 911.677 bp

### Aligning passed L dearborni liver ONT cDNA reads to primary assembly with minimap2

```{bash}

#!/bin/bash
#SBATCH --account=pi-jkoc
#SBATCH --partition=lab-colibri
#SBATCH --qos=pi-jkoc
#SBATCH --job-name=Ld_R1_minimap_index_align
#SBATCH --time=0-48:00:00
#SBATCH --mail-user=snbogan@ucsc.edu
#SBATCH --mail-type=ALL
#SBATCH --output=Ld_R1_minimap_index_align.out
#SBATCH --error=Ld_R1_minimap_index_align.err
#SBATCH --ntasks=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=8
#SBATCH --mem=68GB

# Move directories
cd /hb/home/snbogan/PolarFish/RNAseq/Ldear_run1/alignments

# Load minimap2 and samtools
module load minimap2
module load samtools

# Create inputs, outputs
REFERENCE="/hb/home/snbogan/PolarFish/Long_AFP/new_genomes/Ldear_hifionly.asm.bp.p_ctg.fa"

READS="/hb/home/snbogan/PolarFish/RNAseq/Ldear_run1/20240606_1038_MN32724_FAU44241_e56fb14d/guppy_out_parallel/Ld_liver_rna_ont_r1_gpu1_pass.fastq.gz"

OUTPUT="Ld_R1_liver_pass_minimap2.sam"

# Index L dearborni primary reference genome
echo "Indexing the reference genome..."
minimap2 -d Ld_primary_reference.mmi "$REFERENCE"

# Align with minimap2
echo "Aligning reads to the reference genome..."
minimap2 -ax splice -uf -k14 -t 8 Ld_primary_reference.mmi "$READS" > "$OUTPUT"

# Bam convert and sort sam file
echo "Converting SAM to BAM, sorting, and indexing..."
samtools view -@ 8 -bS "$OUTPUT" | samtools sort -@ 8 -o Ld_R1_liver_pass_minimap2.sorted.bam
samtools index Ld_R1_liver_pass_minimap2.sorted.bam

```

